import streamlit as st
import numpy as np
import pandas as pd
import requests
import pickle
import sklearn
import re
import tqdm
import numpy as np
import pandas as pd
import zipfile
import scipy
import folium
import os
import subprocess

from PIL import Image
from zipfile import ZipFile
from ALS import als_model, rest2idx, idx2rest, data
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from implicit.als import AlternatingLeastSquares as ALS  

st.set_page_config(layout="wide")


project_dir = 'projects'


if not os.path.exists(project_dir):
    st.write("Cloning repository...")
    cmd = 'git clone -b master --single-branch https://github.com/Korea-sehun/projects.git'
    subprocess.check_call(cmd, shell=True)
    st.write("Repository cloned.")
else:
    st.write(f"Directory '{project_dir}' already exists. Skipping clone.")


image_dir = "projects/real_image"
image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))]

def find_photo(menu_list, name_list, base_folder):
    for menu, name in zip(menu_list, name_list):
	    file_name = f"{menu}_{name}.jpg"
	    file_path = os.path.join(base_folder, file_name)
	    return file_path

# ''' Backend '''
franchise_burger = pd.read_csv('df_franchise.csv')
premium_burger = pd.read_csv('df_premium_final.csv')

# ë°ì´í„° ì „ì²˜ë¦¬
# í”„ë¦¬ë¯¸ì—„ ë²„ê±° ê°€ê²© ìˆ«ìí˜• ë°ì´í„°ë¡œ ë°”ê¾¸ëŠ” ì‘ì—…
# 'ì›' ì§€ìš°ê³  ì§„í–‰
premium_burger['price'] = premium_burger['price'].replace({'ì›': '', ',': ''}, regex=True)
# ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ëŠ” ê²½ìš° nan ì²˜ë¦¬
premium_burger['price'] = pd.to_numeric(premium_burger['price'], errors='coerce')
# priceì—ì„œ ê²°ì¸¡ê°’ ìˆëŠ” í–‰ ì œê±°
premium_burger = premium_burger.dropna(subset=['price'])
# ì •ìˆ˜í˜•ìœ¼ë¡œ ë°”ê¾¸ê¸°
premium_burger['price'] = premium_burger['price'].astype(int)
franchise_burger = franchise_burger.rename(columns={
    'brand': 'name',
    'name': 'menu',
})
franchise_burger['menu_input'] = '[' + franchise_burger['name'] + '] ' + franchise_burger['menu']

# í”„ëœì°¨ì´ì¦ˆì—ì„œ ê´€ë ¨ìˆëŠ” í–‰ë§Œ ëª¨ìœ¼ê¸°
filtered_franchise_burger = franchise_burger[[ 'name', 'menu', 'price', 'wordlist', 'patty']]
# í”„ëœì°¨ì´ì¦ˆ, í”„ë¦¬ë¯¸ì—„ í´ë˜ìŠ¤ êµ¬ë¶„
filtered_franchise_burger['class'] = 0
premium_burger['class'] = 1
burger_data = pd.concat([filtered_franchise_burger, premium_burger], ignore_index = True)

burger_data['visitor'] = burger_data['visitor'].fillna('0')
burger_data['blog'] = burger_data['blog'].fillna('0')

burger_data['visitor'] = burger_data['visitor'].str.replace(',', '').astype(int)
burger_data['blog'] = burger_data['blog'].str.replace(',', '').astype(int)

max_visitors = burger_data['visitor'].max()
max_blogs = burger_data['blog'].max()


burger_data['wordlist'] = burger_data['wordlist'].astype(str)

tfidf_vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(' '))
tfidf_matrix = tfidf_vectorizer.fit_transform(burger_data['wordlist'])

# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í™•ì¸
similarity_df = pd.DataFrame(cosine_sim, index=burger_data['name'], columns=burger_data['menu'])
similarity_df.head()

def final_recommendation(burger_data, selected_burger_input, min, max, popularity_min):
    selected_burger = re.sub(r'\[.*?\]\s*', '', selected_burger_input)
    selected_burger_patty = burger_data.loc[burger_data['menu'] == selected_burger, 'patty'].values
    if len(selected_burger_patty) == 0:
        # ì„ íƒëœ ë²„ê±°ê°€ ë°ì´í„°ì— ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
        return pd.DataFrame()
    selected_burger_patty = selected_burger_patty[0]

    final_scores = similarity_df[selected_burger].values
    recommendations_df = pd.DataFrame({
        'id': burger_data['id'].tolist(),
    'menu': burger_data['menu'].tolist(),
    'name': burger_data['name'].tolist(),
    'class': burger_data['class'].tolist(),
    'price': burger_data['price'].tolist(),
    'patty': burger_data['patty'].tolist(),
    'visitor': burger_data['visitor'].tolist(),
    'blog': burger_data['blog'].tolist(),
    'score': final_scores
  })
    filtered_recommendations = recommendations_df[
        (recommendations_df['class'] == 1) &
        (recommendations_df['price'] >= min) &
        (recommendations_df['price'] < max) &
        ((recommendations_df['visitor'] + recommendations_df['blog']) >= popularity_min) &
        (recommendations_df['patty'].str.contains(selected_burger_patty, na = False))
  ]
    filtered_recommendations = filtered_recommendations.drop_duplicates(subset='menu')
    final_recommendations = filtered_recommendations[['id', 'menu', 'name', 'price', 'score']] \
        .sort_values(by='score', ascending=False) \
        .iloc[:10]
    return final_recommendations

# ''' Frontend '''
st.title("[KUBIG 19ê¸° ì¶”ì²œì‹œìŠ¤í…œíŒ€] ìˆ˜ì œë²„ê±° ì¶”ì²œì‹œìŠ¤í…œ")
v = st.write(""" <h2> <b style="color:red"> ìˆ˜ì œë²„ê±° </b> ì¶”ì²œì‹œìŠ¤í…œ ğŸ”</h2>""",unsafe_allow_html=True)
st.write(""" <p> í”„ëœì°¨ì´ì¦ˆ ë²„ê±°ë¡œ ì·¨í–¥ ì €ê²© <b style="color:red">ìˆ˜ì œë²„ê±°</b> ì°¾ê¸°! </p>""",unsafe_allow_html=True)
my_expander = st.expander("Tap to Select a Burger ğŸ”")
selected_burger_name = my_expander.selectbox("ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” í”„ëœì°¨ì´ì¦ˆ ë²„ê±°ëŠ”",franchise_burger['menu_input'])
price_range = my_expander.slider("ê°€ê²© ë²”ìœ„ ì„¤ì •", value=[0, 42500])


if my_expander.button("Recommend"):
    st.text("Here are few Recommendations..")
    result = final_recommendation(burger_data, selected_burger_name, price_range[0], price_range[1], 0)
    menu_list = result['menu'].tolist()
    id_list = result['id'].tolist()
    name_list = result['name'].tolist()
    price_list = result['price'].tolist()
    score_list = result['score'].tolist()
    unique_names = []
    burger_image_path = []	
	
    for name in name_list:
        if name not in unique_names:
            unique_names.append(name)
        if len(unique_names) == 5:
            break  
    related = als_model.similar_items(rest2idx[unique_names[0]])
    array2list = related[0]
    number_list = array2list.tolist()
    result_list = []
    for idx in number_list:
        rest_ids = data[data['restidx'] == idx]['rest_id'].unique()
        for rest_id in rest_ids:
            if rest_id not in unique_names:
                result_list.append(rest_id)
    v = st.write("""<h2> ë‹¹ì‹ ì˜ <b style="color:red"> ìˆ˜ì œë²„ê±° </b> ì·¨í–¥ì€? </h2>""",unsafe_allow_html=True)
    col1,col2,col3,col4,col5=st.columns(5)
    cols=[col1,col2,col3,col4,col5]
    if not menu_list:
        st.write('<b style="color:#E50914"> Sorry, no results found! </b>', unsafe_allow_html=True)
        st.text("ê°€ê²© ë²”ìœ„ë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš” ğŸ˜¢")
    else:
        for i in range(0,5):
			burger_image = find_photo(menu_list[i], name_list[i], base_folder)
			burger_image_path.append(burger_image)
            rank = i + 1
            with cols[i]:
                st.write(f'{rank}ìœ„')
                st.write(f' <b style="color:#E50914"> {menu_list[i]} </b>',unsafe_allow_html=True)
                try:
                    image = Image.open(burger_image_path[i])
                    st.image(image, caption=menu_list[i], use_column_width=True)
                except FileNotFoundError:
                    st.write("[no image]")
                    
                st.write("________")
                st.write(f'<b style="color:#DB4437">ê°€ê²Œëª…</b>:<b> {name_list[i]}</b>',unsafe_allow_html=True)
                st.write(f'<b style="color:#DB4437">   Price  </b>: <b> {price_list[i]} <b> ',unsafe_allow_html=True)
    v = st.write(""" <h2> ë°©ë¬¸í•´ë³´ë©´ ì¢‹ì„ ìˆ˜ì œë²„ê±° <b style="color:red"> ê°€ê²Œ </b> ì¶”ì²œ </h2>""",unsafe_allow_html=True)
    col1,col2,col3,col4,col5=st.columns(5)
    cols=[col1,col2,col3,col4,col5]
    for i in range(0,5):
        rank = i + 1
        with cols[i]:
            st.write(f'{rank}ìœ„')
            st.write(f' <b style="color:#E50914"> {result_list[i]} </b>',unsafe_allow_html=True)
            # st.write("#")
            st.write("________")
    lati = []
    longi = []
    for store_name in result_list:
	    matching_rows = burger_data[burger_data['name'] == store_name]
	    unique_lat_lon = matching_rows[['latitude', 'longitude']].drop_duplicates()
	    lati.extend(unique_lat_lon['latitude'].tolist())
	    longi.extend(unique_lat_lon['longitude'].tolist())
    map_data = pd.DataFrame({
    'lat': lati[0:5],
    'lon': longi[0:5],
    'name': result_list[0:5],
    })
    my_map = folium.Map(
	location=[map_data['lat'].mean(), map_data['lon'].mean()], 
    zoom_start=7)
    for index, row in map_data.iterrows():
	    folium.Marker(
		    location=[row['lat'], row['lon']],   # ê°’ í‘œì‹œ ìœ„ì¹˜ (ìœ„ë„, ê²½ë„)
		    popup=row['name'],                   # íŒì—…ì— ê°€ê²Œ ì´ë¦„ í‘œì‹œ
		    icon=folium.Icon(icon='info-sign')      # ê¸°ë³¸ ì•„ì´ì½˜ ì‚¬ìš© (ì˜µì…˜)
	    ).add_to(my_map)
	    
    st.components.v1.html(my_map._repr_html_(), width=800, height=600)
